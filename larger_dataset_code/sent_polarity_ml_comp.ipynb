{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from nlp_ai_utils import *\n",
    "from chunks_urls import CHUNKS_URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_ENABLE_ONEDNN_OPTS = 0\n",
    "URLS = CHUNKS_URLS\n",
    "LIMIT = 60\n",
    "LARGER_DATASET_PATH = \"../larger_dataset\"\n",
    "PREPROCESSED_CHUNKS_PATH = LARGER_DATASET_PATH + \"/preprocessed_data_chunks/\"\n",
    "BASE_FILE_NAME = \"chunk_\"\n",
    "FILE_FORMAT = \".csv\"\n",
    "ACTUAL_DATA_SHAPE = 6990280\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(urls,limit=0,verbose = 1,base_name = \"\",file_path=\"\",file_format='.csv'):\n",
    "    #downloads all data from their urls\n",
    "    for i,url in enumerate(urls):\n",
    "        if limit:\n",
    "            if i == limit:\n",
    "                return\n",
    "        file_name = base_name + str(i + 1)\n",
    "        #checks if file already exists\n",
    "        if os.path.exists(file_path + file_name + file_format):\n",
    "            print(f\"{file_name} already exists.\")\n",
    "            continue\n",
    "        if i % verbose == 0:\n",
    "            print(f\"Downloading {file_name}...\")\n",
    "        r = requests.get(url)\n",
    "        with open(file_path + file_name + file_format, 'wb') as fd:\n",
    "            for chunk in r.iter_content():\n",
    "                #save file in the current directory of the notebook\n",
    "                fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_file_names(base_name,limit_num):\n",
    "    return [base_name + str(num) for num in range(1,limit_num + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunks(files,file_path = \"\",file_format = \".csv\"):\n",
    "    #reads chunks csvs and converts them to a dataframe format\n",
    "    final_df = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file_path + file + file_format)\n",
    "        final_df.append(df)\n",
    "    #function returns a list of dfs\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all names of downloaded files\n",
    "all_file_names = get_all_file_names(BASE_FILE_NAME,LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all chunks into a list\n",
    "list_dfs = read_chunks(all_file_names,PREPROCESSED_CHUNKS_PATH,FILE_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_up_chunks(dfs):\n",
    "    #adds up all dataframes together\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all chunks into a singular df\n",
    "df = group_up_chunks(list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = df[['text', 'stars']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.reset_index(inplace = True)\n",
    "review_data.drop(['index'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.rename(columns = {'text':'full_review_text','stars':'star_rating'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decide eat aware go take 2 hour begin end try ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ve take lot spin class year nothing compare cl...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family diner buffet eclectic assortment large ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow yummy different delicious favorite lamb cu...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cute interior owner give u tour upcoming patio...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990275</th>\n",
       "      <td>late addition service iccu apple pay iccu debi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990276</th>\n",
       "      <td>spot offer great affordable east weekend paddl...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990277</th>\n",
       "      <td>home depot need get lot demential lumber seem ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990278</th>\n",
       "      <td>m feel like ignore caloriecounting indulge fla...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990279</th>\n",
       "      <td>locate walk district nashville s bit way u mis...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6990236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          full_review_text  star_rating\n",
       "0        decide eat aware go take 2 hour begin end try ...          3.0\n",
       "1        ve take lot spin class year nothing compare cl...          5.0\n",
       "2        family diner buffet eclectic assortment large ...          3.0\n",
       "3        wow yummy different delicious favorite lamb cu...          5.0\n",
       "4        cute interior owner give u tour upcoming patio...          4.0\n",
       "...                                                    ...          ...\n",
       "6990275  late addition service iccu apple pay iccu debi...          5.0\n",
       "6990276  spot offer great affordable east weekend paddl...          5.0\n",
       "6990277  home depot need get lot demential lumber seem ...          4.0\n",
       "6990278  m feel like ignore caloriecounting indulge fla...          5.0\n",
       "6990279  locate walk district nashville s bit way u mis...          3.0\n",
       "\n",
       "[6990236 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_data.isnull().sum()\n",
    "review_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = review_data['full_review_text']\n",
    "y = review_data['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.Series([str(text) for text in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_review_text    44\n",
       "star_rating          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decide eat aware go take 2 hour begin end try ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ve take lot spin class year nothing compare cl...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family diner buffet eclectic assortment large ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow yummy different delicious favorite lamb cu...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cute interior owner give u tour upcoming patio...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990275</th>\n",
       "      <td>late addition service iccu apple pay iccu debi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990276</th>\n",
       "      <td>spot offer great affordable east weekend paddl...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990277</th>\n",
       "      <td>home depot need get lot demential lumber seem ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990278</th>\n",
       "      <td>m feel like ignore caloriecounting indulge fla...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990279</th>\n",
       "      <td>locate walk district nashville s bit way u mis...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6990236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          full_review_text  star_rating\n",
       "0        decide eat aware go take 2 hour begin end try ...          3.0\n",
       "1        ve take lot spin class year nothing compare cl...          5.0\n",
       "2        family diner buffet eclectic assortment large ...          3.0\n",
       "3        wow yummy different delicious favorite lamb cu...          5.0\n",
       "4        cute interior owner give u tour upcoming patio...          4.0\n",
       "...                                                    ...          ...\n",
       "6990275  late addition service iccu apple pay iccu debi...          5.0\n",
       "6990276  spot offer great affordable east weekend paddl...          5.0\n",
       "6990277  home depot need get lot demential lumber seem ...          4.0\n",
       "6990278  m feel like ignore caloriecounting indulge fla...          5.0\n",
       "6990279  locate walk district nashville s bit way u mis...          3.0\n",
       "\n",
       "[6990236 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../pickle_files'):\n",
    "    os.mkdir('../pickle_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Pickle File.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"../pickle_files/word2vec_model_sklearn.pickle\"):\n",
    "    print(\"Creating Embedding From Scratch.\")\n",
    "    word2vec_model_sklearn = count_model.fit_transform(X.apply(lambda x: np.str_(x)))\n",
    "    pickle_out = open(\"../pickle_files/word2vec_model_sklearn.pickle\",'wb')\n",
    "    pickle.dump(word2vec_model_sklearn,pickle_out)\n",
    "    pickle_out.close()\n",
    "else:\n",
    "    print(\"Found Pickle File.\")\n",
    "    word2vec_model_sklearn = pickle.load(open(\"../pickle_files/word2vec_model_sklearn.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_sklearn_array = word2vec_model_sklearn.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = create_train_test_split(word2vec_model_sklearn_array,y,test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_resampler = SMOTE(random_state=RANDOM_STATE)\n",
    "x_train,y_train = smote_resampler.fit_resample(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sent_polarity_info = [sid.polarity_scores(review) for review in review_data['full_review_text']]\n",
    "\n",
    "sent_polarity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sentiment = [classify_sentiment(scores) for scores in sent_polarity_info]\n",
    "\n",
    "sent_polarity = [extract_sent_polarity(scores) for scores in sent_polarity_info]\n",
    "\n",
    "\n",
    "review_data['str_sent'] = review_sentiment\n",
    "\n",
    "review_data['sent_polarity'] = sent_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = translate_labels(y)\n",
    "y_true_sent = encode_sent(sentiment_labels)\n",
    "y_pred_sent = encode_sent(df['str_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_true_sent,y_pred_sent))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100,random_state=RANDOM_STATE)\n",
    "svm_clf = SVC(kernel='rbf',random_state=RANDOM_STATE)\n",
    "mnnb_clf = MultinomialNB(random_state = RANDOM_STATE)\n",
    "xgb_clf = XGBClassifier(random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_xgb,y_test_xgb = adjust_xgb_labels(y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(x_train,y_train)\n",
    "svm_clf.fit(x_train,y_train)\n",
    "mnnb_clf.fit(x_train,y_train)\n",
    "xgb_clf.fit(x_train,y_train_xgb)\n",
    "y_pred_rf = rf_clf.predict(x_test)\n",
    "y_pred_svm = svm_clf.predict(x_test)\n",
    "y_pred_mnnb = mnnb_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(rf_clf,x_test,y_test,y_pred_rf,word2vec_model_sklearn_array,y)\n",
    "show_metrics(svm_clf,x_test,y_test,y_pred_rf,word2vec_model_sklearn_array,y)\n",
    "show_metrics(mnnb_clf,x_test,y_test,y_pred_rf,word2vec_model_sklearn_array,y)\n",
    "show_metrics(xgb_clf,x_test,y_test_xgb,y_pred_rf,word2vec_model_sklearn_array,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
