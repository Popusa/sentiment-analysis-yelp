{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "best_params = pickle.load(open(\"../pickle_files/baseline.pickle\", \"rb\"))\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy nltk scikit-learn wordcloud seaborn gensim tensorflow imblearn xgboost matplotlib unrar pyunpack more-itertools patool keras-tqdm > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68646ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8498fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_ai_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498acadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LARGER_DATASET_PATH = '../larger_dataset/'\n",
    "PREPROCESSED_CHUNKS_PATH = LARGER_DATASET_PATH + 'preprocessed_data_chunks/'\n",
    "if not os.path.exists(LARGER_DATASET_PATH):\n",
    "    os.mkdir(LARGER_DATASET_PATH)\n",
    "\n",
    "if not os.path.exists(PREPROCESSED_CHUNKS_PATH):\n",
    "    os.mkdir(PREPROCESSED_CHUNKS_PATH)\n",
    "\n",
    "#get all names of downloaded files\n",
    "\n",
    "all_file_names = get_all_file_names('chunk_',60)\n",
    "#read all chunks into a list\n",
    "list_dfs = read_chunks(all_file_names,PREPROCESSED_CHUNKS_PATH,'.csv')\n",
    "#concatenate all chunks into a singular df\n",
    "df = group_up_chunks(list_dfs)\n",
    "#check how much of the data was actually downloaded\n",
    "percent_loaded = check_no_missing_data(df.shape[0],6990280)\n",
    "percent_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d28105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    3231627\n",
       "4.0    1452918\n",
       "1.0    1069561\n",
       "3.0     691934\n",
       "2.0     544240\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9135968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../larger_dataset/data_chunks/chunk_1.csv\")\n",
    "df2 = pd.read_csv(\"../larger_dataset/preprocessed_data_chunks/chunk_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [len(text.split()) for text in df1['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e338e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df1['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071916bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_corpus(remove_stop_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c87fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words(process_corpus(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_corpus(remove_stop_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['love','hate','peace','pizza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266de0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "sent_polarity_words = [sid.polarity_scores(item) for item in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_polarity_words[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../smaller_dataset/yelp coffee/raw_yelp_review_data_processed.csv\")\n",
    "df_unprocessed = pd.read_csv(\"../smaller_dataset/yelp coffee/raw_yelp_review_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['full_review_text']\n",
    "\n",
    "y = df['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe13c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315855f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sent(sentiments,positive_label = 1,negative_label = 2,neutral_label = 3):\n",
    "    \"\"\"\n",
    "    This function takes in all translated labels (labels transformed for star ratings to sentiments), and converts them to numerical values.\n",
    "\n",
    "    positive_label: x => Positive Integer, Default = 1\n",
    "\n",
    "    negative_label: x => Positive Integer, Default = 2\n",
    "\n",
    "    neutral_label: x => Positive Integer, Default = 3\n",
    "\n",
    "    \"\"\"\n",
    "    translated_labels = sentiments\n",
    "    encoded_sent = []\n",
    "    for label in translated_labels:\n",
    "        if label == 'Positive Sentiment':\n",
    "            encoded_sent.append(positive_label)\n",
    "        elif label == 'Negative Sentiment':\n",
    "            encoded_sent.append(negative_label)\n",
    "        else:\n",
    "            encoded_sent.append(neutral_label)\n",
    "    return encoded_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ed55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_labels = translate_labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = encode_sent(translated_labels,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9628ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_labels = translate_labels(y)\n",
    "y = pd.Series(encode_sent(translated_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef84b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_classes_count(y,start_label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=list(y.unique()), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_COUNT = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ratings_pie(y,use_dict = samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d37679",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = range(1,6)\n",
    "test2 = [1,2,3,4,5]\n",
    "\n",
    "print(test1 == test2)\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaae7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_review(text):\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = [tokenize_review(review) for review in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=reviews_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "# model.save(\"test_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d35cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(reviews_tokens), model.vector_size))\n",
    "labels = y\n",
    "for i, review in enumerate(reviews_tokens):\n",
    "    for word in review:\n",
    "        if word in model.wv:\n",
    "            X[i] += model.wv[word]\n",
    "    X[i] /= len(reviews_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe317b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,labels,stratify=labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state = 42)\n",
    "# x_train,y_train = smote.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8614f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7303511",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = \"I like this place, but it is not my favourite at all.\"\n",
    "test_token = nltk.word_tokenize(test_review)\n",
    "test_vector = np.zeros(model.vector_size)\n",
    "for word in test_token:\n",
    "    if word in model.wv:\n",
    "        test_vector += model.wv[word]\n",
    "test_vector /= len(test_token)\n",
    "predicted_label = clf.predict([test_vector])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
